{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Import les modules suivants:\n",
    "\n",
    "# requests & get\n",
    "# BeautifulSoup\n",
    "# Time & sleep\n",
    "# Random & randint\n",
    "# IPython & clear_output - Optionnel trop complexe\n",
    "# Pandas\n",
    "\n",
    "# Chaque page de recherche contient toujours 50 films\n",
    "# L'url de recherche avec first_film prendra les valeurs 1, 51, 101, ...\n",
    "# 'http://www.imdb.com/search/title?release_date='+ year_url + '&sort=num_votes, desc&start='+ start\n",
    "#url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2017-12-30\"\n",
    "#response = get(url)\n",
    "\n",
    "# 2. Déclarer les variables starts et year_url en précisant les valeurs permettant de modifier l'URL\n",
    "# Créer des boucles for avec la fonction range()\n",
    "\n",
    "# 3. Redéclarer les listes précédemment crées pour notre script sur une seule page pour qu'elles\n",
    "# deviennent de nouveau vides\n",
    "\n",
    "# Titre\n",
    "# Année\n",
    "# Note imdb\n",
    "# Metascore\n",
    "# Nombre de  votes\n",
    "\n",
    "# 4. Préparer l'écran d'affichage de la boucle # Trop complexe à retirer \n",
    "\n",
    "# 5. Écrire une boucle qui fait varier le paramètre year_url de l'URL avec les valeurs de la liste years_url\n",
    "\n",
    "  # 6. Écrire une boucle qui fait varier le paramètre start de l'URL avec les valeurs de la liste starts\n",
    "\n",
    "    # 7. Faire une requête GET sur la boucle des pages\n",
    "    \n",
    "    # 8. Pauser la boucle sur un intervalle de 8 à 15 secondes\n",
    "    \n",
    "    # 9. Afficher à l'écran le temps de requêtes # Trop complexe\n",
    "   \n",
    "    # 10. Ajouter un avertissement pour tout code status différent de 200 \n",
    "    # Condition if\n",
    "   \n",
    "    # 11. Arrêter la boucle si le nombre de requêtes est supérieur à 72 pages\n",
    "    # Break\n",
    "    \n",
    "    # 12. Convertir le contenu HTML response en un objet BeautifulSoup\n",
    "    \n",
    "    # 13. Sélectionner les 50 films de chaque page\n",
    "   \n",
    "    # 14. Écrire une boucle qui parcourt tout les containers\n",
    " \n",
    "      # 15. Extraire les informations de chaque container si celui-ci a un Metascore\n",
    "        # Attention au Metascore\n",
    "      \n",
    "        # 16. Extraire le titre\n",
    "      \n",
    "        # 17. Extraire l'année\n",
    "      \n",
    "        # 18. Extraire la note imdb\n",
    "    \n",
    "        # 19. Extraire le metascore\n",
    "        # Condition pour évite le crash du script \n",
    "       \n",
    "        # 20. Extraire le nombre de votes avec attrs/data value \n",
    "        # A détailler sur la méthode\n",
    "        \n",
    "# A voir optionnel        \n",
    "        \n",
    "# 21. Afficher le résult dans un tableur avec panda\n",
    "# Utiliser les listes et le format dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
