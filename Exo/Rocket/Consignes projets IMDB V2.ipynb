{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chaque page de recherche contient toujours 50 films\n",
    "\n",
    "# L'url de recherche avec first_film prendra les valeurs 1, 51, 101, ...\n",
    "# Exemple d'url: \"https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2017-12-30\"\n",
    "\n",
    "# L'url avec les variables de page et d'année ressemblera à ceci dans la requête Get\n",
    "#'http://www.imdb.com/search/title?release_date='+ year_url + '&sort=num_votes, desc&start='+ start\n",
    "\n",
    "# 1.Import les modules suivants:\n",
    "\n",
    "# requests & get\n",
    "# BeautifulSoup\n",
    "# Time & sleep\n",
    "# Random & randint\n",
    "# Pandas\n",
    "\n",
    "\n",
    "# 2. Déclarer les variables starts et year_url en précisant les valeurs permettant de modifier l'URL\n",
    "# Créer des boucles for avec la fonction range() pour itérer les pages de 1 à 201 et les annnées de 2000 à 2018\n",
    "\n",
    "# 3.Déclarer des listes vides pour stocker les données\n",
    "# Titre\n",
    "# Année\n",
    "# Note imdb\n",
    "# Metascore\n",
    "# Nombre de  votes\n",
    " \n",
    "\n",
    "# 5. Écrire une boucle qui fait varier le paramètre year_url de l'URL avec les valeurs de la liste years_url\n",
    "\n",
    "  # 6. Écrire une seconde boucle dans la boucle qui fait varier le paramètre start de l'URL avec les valeurs de la liste starts\n",
    "\n",
    "    # 7. Faire une requête GET sur la boucle des pages\n",
    "    \n",
    "    # 8. Pauser la boucle sur un intervalle de 8 à 15 secondes avec sleep randint\n",
    "   \n",
    "    # 10. Ajouter un avertissement pour tout code status différent de 200 \n",
    "    # Condition if différent de 200\n",
    "     \n",
    "    # 12. Convertir le contenu HTML response en un objet BeautifulSoup\n",
    "    \n",
    "    # 13. Sélectionner les 50 films de chaque page\n",
    "   \n",
    "    # 14. Écrire une boucle qui parcourt tout les containers\n",
    " \n",
    "      # 15. Extraire les informations de chaque container si celui-ci a un Metascore\n",
    "        # Ajouter une condition if not None\n",
    "      \n",
    "        # 16. Extraire le titre\n",
    "      \n",
    "        # 17. Extraire l'année\n",
    "      \n",
    "        # 18. Extraire la note imdb\n",
    "    \n",
    "        # 19. Extraire le metascore \n",
    "       \n",
    "        # 20. Extraire le nombre de votes avec attrs/data value \n",
    "        # A détailler sur la méthode\n",
    "              \n",
    "        \n",
    "# 21. Afficher le résult dans un tableur avec panda\n",
    "# Utilisez les listes et le format dictionnaire"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
